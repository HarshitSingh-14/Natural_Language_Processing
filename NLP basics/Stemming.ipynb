{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594751d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshitsingh/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d3bf2",
   "metadata": {},
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420f09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a18fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run', 'runner', 'ran','runs', 'easily', 'fairly','fairness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91600514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run         -->    run\n",
      "runner      -->    runner\n",
      "ran         -->    ran\n",
      "runs        -->    run\n",
      "easily      -->    easili\n",
      "fairly      -->    fairli\n",
      "fairness    -->    fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"{word :{10}}  -->    {p_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110df910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ff3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae8d5a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run         -->    run\n",
      "runner      -->    runner\n",
      "ran         -->    ran\n",
      "runs        -->    run\n",
      "easily      -->    easili\n",
      "fairly      -->    fair\n",
      "fairness    -->    fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"{word :{10}}  -->    {s_stemmer.stem(word)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95872839",
   "metadata": {},
   "source": [
    "### Different for differnt stem type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3e3ba",
   "metadata": {},
   "source": [
    "## Lematisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6b3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c147ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21554657",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1= nlp(u\"I am runner so i love running. A run every day makes one healthy , fit , strong in stronger \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec96321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t\t PRON \t\t -PRON- \t\t\t 561228191312463089\n",
      "am \t\t VERB \t\t be \t\t\t 10382539506755952630\n",
      "runner \t\t ADV \t\t runner \t\t\t 12640964157389618806\n",
      "so \t\t ADV \t\t so \t\t\t 9781598966686434415\n",
      "i \t\t PRON \t\t i \t\t\t 5097672513440128799\n",
      "love \t\t VERB \t\t love \t\t\t 3702023516439754181\n",
      "running \t\t VERB \t\t run \t\t\t 12767647472892411841\n",
      ". \t\t PUNCT \t\t . \t\t\t 12646065887601541794\n",
      "A \t\t DET \t\t a \t\t\t 11901859001352538922\n",
      "run \t\t NOUN \t\t run \t\t\t 12767647472892411841\n",
      "every \t\t DET \t\t every \t\t\t 2739543297294151269\n",
      "day \t\t NOUN \t\t day \t\t\t 1608482186128794349\n",
      "makes \t\t VERB \t\t make \t\t\t 9614445426764226664\n",
      "one \t\t NUM \t\t one \t\t\t 17454115351911680600\n",
      "healthy \t\t ADJ \t\t healthy \t\t\t 5379644128261274187\n",
      ", \t\t PUNCT \t\t , \t\t\t 2593208677638477497\n",
      "fit \t\t ADJ \t\t fit \t\t\t 6388973655490464457\n",
      ", \t\t PUNCT \t\t , \t\t\t 2593208677638477497\n",
      "strong \t\t ADJ \t\t strong \t\t\t 12618292361406372890\n",
      "in \t\t ADP \t\t in \t\t\t 3002984154512732771\n",
      "stronger \t\t ADJ \t\t strong \t\t\t 12618292361406372890\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text, '\\t\\t', token.pos_, '\\t\\t' , token.lemma_ ,'\\t\\t\\t', token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df0f49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print (f' {token. text: {12}} {token.pos_:{6}} {token. lemma:<{22}} {token. lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15aa61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
