{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c0078f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bac8d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q6/qq72m1_54ll6wb3r48wv1zzm0000gn/T/ipykernel_1504/1858266218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_trf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_trf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/en_core_web_trf/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m     )\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     nlp = load_model_from_config(\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_config\u001b[0;34m(config, meta, vocab, disable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mauto_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_fill\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m     )\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, vocab, disable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0;31m# then we would load them twice at runtime: once when we make from config,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;31m# and then again when we load from disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m         \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mafter_creation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafter_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab, max_length, meta, create_tokenizer, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mvectors_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vectors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.create_vocab\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/vectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/thinc/backends/__init__.py\u001b[0m in \u001b[0;36mget_current_ops\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;34m\"\"\"Get the current backend object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mrequire_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/thinc/util.py\u001b[0m in \u001b[0;36mrequire_cpu\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_current_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mset_current_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mset_torch_tensor_type_for_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/thinc/backends/__init__.py\u001b[0m in \u001b[0;36mget_ops\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0m_import_extra_cpu_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops_by_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops_by_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"apple\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/thinc/backends/__init__.py\u001b[0m in \u001b[0;36m_import_extra_cpu_backends\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_import_extra_cpu_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mthinc_apple_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAppleOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/thinc_apple_ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAppleOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/thinc_apple_ops/ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumpyOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloats2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mblas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/thinc_apple_ops/blas.pyx\u001b[0m in \u001b[0;36minit thinc_apple_ops.blas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "import en_core_web_trf\n",
    "\n",
    "nlp = en_core_web_trf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddfd0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"We are n't going to go for  ateleast 3 research papers ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ec6366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "are\n",
      "n't\n",
      "going\n",
      "to\n",
      "go\n",
      "for\n",
      " \n",
      "ateleast\n",
      "3\n",
      "research\n",
      "papers\n",
      ";)\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6347e0",
   "metadata": {},
   "source": [
    "### Parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cc4d11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We PRON nsubj\n",
      "are VERB aux\n",
      "n't ADV neg\n",
      "going VERB ROOT\n",
      "to PART aux\n",
      "go VERB xcomp\n",
      "for ADP prep\n",
      "  SPACE \n",
      "ateleast NOUN advmod\n",
      "3 NUM nummod\n",
      "research NOUN compound\n",
      "papers NOUN npadvmod\n",
      ";) PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "    print(token.text , token.pos_ , token.dep_)    # dep -> token dependencies\n",
    "    \n",
    "# ns -> nominal subject \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dfabb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x7f8d45506150>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x7f8cf04f1530>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x7f8cf04f1ad0>)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d59bfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c6568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1488e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7ee8453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRON'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e1c92",
   "metadata": {},
   "source": [
    "#### Lemmas -> (The base form of the word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41fb04c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "print(doc[3].text)\n",
    "print(doc[3].lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02162c8d",
   "metadata": {},
   "source": [
    "#### Simple parts of speech & detailed tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12f3977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADV\n"
     ]
    }
   ],
   "source": [
    "print(doc[2].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5b17a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB / adverb\n"
     ]
    }
   ],
   "source": [
    "print(doc[2].tag_ +  ' / ' + spacy.explain(doc[2].tag_)) # full explian "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79193928",
   "metadata": {},
   "source": [
    "#### Word shapes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f96d11e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are:xxx\n",
      "to:xx\n"
     ]
    }
   ],
   "source": [
    "print(doc[1].text + ':' + doc[1].shape_)\n",
    "print(doc[4].text + ':' + doc[4].shape_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8255aa62",
   "metadata": {},
   "source": [
    "#### Boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b236e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We          is stop or not-->  False\n",
      "are         is stop or not-->  True\n",
      "n't         is stop or not-->  False\n",
      "going       is stop or not-->  False\n",
      "to          is stop or not-->  True\n",
      "go          is stop or not-->  True\n",
      "for         is stop or not-->  True\n",
      "            is stop or not-->  False\n",
      "ateleast    is stop or not-->  False\n",
      "3           is stop or not-->  False\n",
      "research    is stop or not-->  False\n",
      "papers      is stop or not-->  False\n",
      ";)          is stop or not-->  False\n"
     ]
    }
   ],
   "source": [
    "for i in doc:\n",
    "    print(f\"{i.text:{10}}  is stop or not-->  {i.is_stop}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374a2d4",
   "metadata": {},
   "source": [
    "## SPans "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7049c1",
   "metadata": {},
   "source": [
    "#### Large Doc objects can be hard to work with at times. A span is a slice of Doc object in the form Doc [start:stop] ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "858869ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'Although commonly attributed to John Lennon from his song \"Beautiful \\\n",
    "the phrase \"Life is what happens to us while we are making other plans was writ\\\n",
    "cartoonist. Allen. Saunders and published in Reader\\'s Digest in 1957, when Lennon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78c452d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful the phrase \"Life is what happens to us while we are making other plans was writcartoonist.\n"
     ]
    }
   ],
   "source": [
    "life_quote = doc2[10:29]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2564a90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)   # span -> a part of a larger document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "09fa5292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b144a2b",
   "metadata": {},
   "source": [
    "#### Spaning to break.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c659647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u\"This is the first sentence. This is another sentence. This is the last sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "03c3d1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc3.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0edc0908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[0]   # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c3d091ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3[0].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52eb2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
